{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "b'\\x1c\\x11\\x0f\\x01\\x0e'\n",
      "2\n",
      "b'davisbase_tablesrowidINT\\x01NO'\n",
      "27\n",
      "5\n",
      "b'\\x1c\\x16\\x10\\x01\\x0e'\n",
      "2\n",
      "b'davisbase_tablestable_nameTEXT\\x02NO'\n",
      "33\n",
      "5\n",
      "b'\\x1d\\x11\\x0f\\x01\\x0e'\n",
      "2\n",
      "b'davisbase_columnsrowidINT\\x01NO'\n",
      "28\n",
      "5\n",
      "b'\\x1d\\x16\\x10\\x01\\x0e'\n",
      "2\n",
      "b'davisbase_columnstable_nameTEXT\\x02NO'\n",
      "34\n",
      "5\n",
      "b'\\x1d\\x17\\x10\\x01\\x0e'\n",
      "2\n",
      "b'davisbase_columnscolumn_nameTEXT\\x03NO'\n",
      "35\n",
      "5\n",
      "b'\\x1d\\x15\\x10\\x01\\x0e'\n",
      "2\n",
      "b'davisbase_columnsdata_typeTEXT\\x04NO'\n",
      "33\n",
      "5\n",
      "b'\\x1d\\x1c\\x13\\x01\\x0e'\n",
      "2\n",
      "b'davisbase_columnsordinal_positionTINYINT\\x05NO'\n",
      "43\n",
      "5\n",
      "b'\\x1d\\x17\\x10\\x01\\x0e'\n",
      "2\n",
      "b'davisbase_columnsis_nullableTEXT\\x06NO'\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import struct\n",
    "import sys\n",
    "from datetime import datetime, time\n",
    "\n",
    "\n",
    "############################################################################\n",
    "\n",
    "def check_input(command):\n",
    "    if len(command)==0:\n",
    "        pass\n",
    "\n",
    "    elif command[-1]!=\";\":\n",
    "        print(\"All commands end with semicolon.\")\n",
    "\n",
    "    elif command == \"help;\":\n",
    "        help()\n",
    "\n",
    "    elif command == \"show tables;\":\n",
    "        show_tables()\n",
    "\n",
    "    elif command[0:len(\"create table \")] == \"create table \":\n",
    "        create_table(command)\n",
    "\n",
    "    elif command[0:len(\"drop table \")] == \"drop table \":\n",
    "        drop_table(command)\n",
    "\n",
    "    elif command[0:len(\"create index \")] == \"create index \":\n",
    "        create_index(command)\n",
    "\n",
    "    elif command[0:len(\"insert \")] == \"insert \":\n",
    "        insert_into(command)\n",
    "\n",
    "    elif command[0:len(\"delete \")] == \"delete \":\n",
    "        insert_into(command)\n",
    "\n",
    "    elif command[0:len(\"update \")] == \"update \":\n",
    "        insert_into(command)\n",
    "\n",
    "    elif command[0:len(\"select \")] == \"select \":\n",
    "        query(command)\n",
    "\n",
    "    elif command == \"exit;\":\n",
    "        return True\n",
    "\n",
    "    elif command == \"test;\":\n",
    "        return True\n",
    "\n",
    "    else:\n",
    "        print(\"Command \\\"{}\\\" not recognized\".format(command))\n",
    "\n",
    "####################################################################\n",
    "#TABLE FUNCTIONS for Harrison to complete\n",
    "\n",
    "def initialize_file(table_name, is_table):\n",
    "    \"\"\"Creates a file and writes the first, empty page (root)\"\"\"\n",
    "    if is_table:\n",
    "        file_type = \".tbl\"\n",
    "    else:\n",
    "        file_type = '.ndx'\n",
    "\n",
    "    if os.path.exists(table_name+file_type):\n",
    "        os.remove(table_name+file_type)\n",
    "\n",
    "    with open(table_name+file_type, 'w+') as f:\n",
    "        pass\n",
    "    write_new_page(table_name, is_table, False, 0, -1)\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def write_new_page(table_name, is_table, is_interior, rsibling_rchild, parent):\n",
    "    \"\"\"Writes a empty page to the end of the file with an appropriate header for the kind of table/index\"\"\"\n",
    "    assert(type(is_table)==bool)\n",
    "    assert(type(is_interior)==bool)\n",
    "    assert(type(rsibling_rchild)==int)\n",
    "    assert(type(parent)==int)\n",
    "\n",
    "    is_leaf = not is_interior\n",
    "    is_index = not is_table\n",
    "    if is_table:\n",
    "        file_type = \".tbl\"\n",
    "    else:\n",
    "        file_type = '.ndx'\n",
    "\n",
    "    file_size = os.path.getsize(table_name + file_type)\n",
    "\n",
    "    with open(table_name + file_type, 'wb') as f:\n",
    "        f.seek(2,0) #seek end of file\n",
    "        f.write(struct.pack(str(PAGE_SIZE-2)+'x')) #write PAGE_SIZE placeholder bytes\n",
    "        #Header\n",
    "        f.seek(0, file_size)\n",
    "        #first byte says what kind of page it is\n",
    "        if is_table and is_interior:\n",
    "            f.write(b'\\x05')\n",
    "        elif is_table and is_leaf:\n",
    "            f.write(b'\\x0d')\n",
    "        elif is_index and is_interior:\n",
    "            f.write(b'\\x02')\n",
    "        elif is_index and is_leaf:\n",
    "            f.write(b'\\x0a')\n",
    "        else:\n",
    "             raise ValueError(\"Page must be table/index\")\n",
    "        f.write(b'\\x00') #unused\n",
    "        f.write(struct.pack(endian+'hhii2x', 0, PAGE_SIZE, rsibling_rchild, parent))\n",
    "        return file_size/PAGE_SIZE\n",
    "\n",
    "def dtype_to_int(dtype):\n",
    "    \"\"\"based on the documentation, each dtype has a single-digit integer encoding\"\"\"\n",
    "    dtype = dtype.lower()\n",
    "    mapping = {\"null\":0,\"tinyint\":1, \"smallint\":2, \"int\":3, \"bigint\":4, \"long\":4, 'float':5, \"double\":6, \"year\":8, \"time\":9, \"datetime\":10, \"date\":11, \"text\":12}\n",
    "    return mapping[dtype]\n",
    "\n",
    "\n",
    "def int_to_fstring(key):\n",
    "    \"\"\"format string for use in struct.pack/struct.unpack\"\"\"\n",
    "    int2packstring={\n",
    "    2:'h', 3:'i', 4:'q', 5:'f', 6:'d',\n",
    "    9:'i', 10:'Q', 11:'Q' }\n",
    "    return int2packstring[key]\n",
    "\n",
    "def schema_to_int(schema, values):\n",
    "    \"\"\"given a list of data types ex [int, year] ,convert to single-digit integer appropriate.\"\"\"\n",
    "    dtypes = [dtype_to_int(dt) for dt in schema]\n",
    "    for i, val in enumerate(values):\n",
    "        if val==None: #regardless of the col dtype, if null-> dt = 0\n",
    "            dtypes[i]=0\n",
    "            continue\n",
    "        elif dtypes[i]==12: #add the len of the string to dtype\n",
    "            dtypes[i]+=len(val)\n",
    "    return dtypes\n",
    "\n",
    "def get_dt_size(dt):\n",
    "    \"\"\"given the single-digit encoding for data type return the number of bytes this data takes\"\"\"\n",
    "    if dt==0:\n",
    "        return 0\n",
    "    if dt in [1,8]:\n",
    "        return 1\n",
    "    elif dt in [2]:\n",
    "        return 2\n",
    "    elif dt in [3,5,9]:\n",
    "        return 4\n",
    "    elif dt in [4,6,10,11]:\n",
    "        return 8\n",
    "    elif dt>=12:\n",
    "        return dt-12\n",
    "    else:\n",
    "        raise ValueError(\"what happened????\")\n",
    "\n",
    "\n",
    "def date_to_bytes(date, time=False):\n",
    "    if not time:\n",
    "        return struct.pack(\">q\", int(round(date.timestamp() * 1000)))\n",
    "    else:\n",
    "        return struct.pack(\">i\", int(round(date.timestamp() * 1000)))\n",
    "\n",
    "def bytes_to_dates(bt, time=False):\n",
    "    if not time:\n",
    "        return datetime.fromtimestamp((struct.unpack(\">q\", bt)[0])/1000)\n",
    "    else:\n",
    "        return datetime.fromtimestamp((struct.unpack(\">i\", bt)[0])/1000)\n",
    "\n",
    "def time_to_byte(t):\n",
    "    d =  datetime(1970,1,2,t.hour,t.minute, t.microsecond)\n",
    "    print(d)\n",
    "    return date_to_bytes(d, time=True)\n",
    "\n",
    "def byte_to_time(bt):\n",
    "    return bytes_to_dates(bt, time=True).time()\n",
    "\n",
    "\n",
    "def val_dtype_to_byte(val, dt):\n",
    "    \"\"\"given a value and a single-digit dtype rep, covert to binary string\"\"\"\n",
    "    if val == None: #NULL\n",
    "        return b''\n",
    "    if dt==1: #one byte int\n",
    "        return val.to_bytes(1, byteorder=sys.byteorder, signed=True)\n",
    "    if dt==8: #one byte year relative to 2000\n",
    "        return (val-2000).to_bytes(1, byteorder=sys.byteorder, signed=True)\n",
    "    if dt in [2,3,4,5,6]: #alldtypes i can convert with struct object\n",
    "        return struct.pack(int_to_fstring(dt), val)\n",
    "    if dt in [10,11]: #datetime, date objects\n",
    "        return date_to_bytes(val)\n",
    "    if dt==9: #time object\n",
    "        return time_to_byte(val)\n",
    "    elif dt>=12:  #look for text\n",
    "        return val.encode('ascii')\n",
    "\n",
    "def dtype_byte_to_val(dt, byte_str):\n",
    "    \"\"\"Given the single-digit dtype encoding and byte string of approp size, returns Python value\"\"\"\n",
    "    if dt==0:  #null type\n",
    "        return None\n",
    "    elif dt==1: #onebyteint\n",
    "        return int.from_bytes(byte_str, byteorder=sys.byteorder, signed=False)\n",
    "    elif dt==8: #one byte year\n",
    "        return int.from_bytes(byte_str, byteorder=sys.byteorder, signed=False)+2000\n",
    "    elif dt in [2,3,4,5,6]: #alldtypes i can convert with struct object\n",
    "        return struct.unpack(int_to_fstring(dt), byte_str)[0]\n",
    "    if dt in [10,11]: #datetime, dateobjects\n",
    "        return bytes_to_dates(byte_str)\n",
    "    if dt==9:#time\n",
    "        return byte_to_time(byte_str)\n",
    "    elif dt>=12:  #text\n",
    "        return byte_str.decode(\"utf-8\")\n",
    "    else:\n",
    "         raise ValueError(\"dtype_byte_to_val????\")\n",
    "\n",
    "def table_values_to_payload(schema, value_list):\n",
    "    \"\"\"given a list of database string formatted datatypes ['int'] and an assoc\n",
    "    list of values with NULL=None\n",
    "\n",
    "    returns a bytestring of all elements in value_list and a single-digit repr of the data types\"\"\"\n",
    "    dtypes = schema_to_int(schema, value_list)\n",
    "    byte_string = b''\n",
    "    for val, dt in zip(value_list, dtypes):\n",
    "        byte_val = val_dtype_to_byte(val, dt)\n",
    "\n",
    "        byte_string += byte_val\n",
    "    return byte_string, dtypes\n",
    "\n",
    "def table_payload_to_values(payload):\n",
    "    \"\"\"\n",
    "    Takes the entire bitstring payload and outputs the values in a list (None=Null)\n",
    "    \"\"\"\n",
    "    num_columns = payload[0]\n",
    "    temp = payload[1:]\n",
    "    dtypes =  temp[:num_columns]\n",
    "    temp = temp[num_columns:]\n",
    "    print(num_columns)\n",
    "    print(dtypes)\n",
    "    i = 0\n",
    "    values = []\n",
    "    for dt in dtypes:\n",
    "        element_size = get_dt_size(dt)\n",
    "        byte_str = temp[i:i+element_size]\n",
    "        values.append(dtype_byte_to_val(dt, byte_str))\n",
    "        i+=element_size\n",
    "    print(element_size)\n",
    "    print(temp)\n",
    "    print(i)\n",
    "    assert(i==len(temp))\n",
    "    return values\n",
    "\n",
    "def index_dtype_value_rowids_to_payload(index_dtype, index_value, rowid_list):\n",
    "    \"\"\"\n",
    "    given list of database string dtype reps ['int'] single value of index, and list of integers\n",
    "\n",
    "    returns the bytestring payload for an index cell\n",
    "    \"\"\"\n",
    "    dt = schema_to_int([index_dtype], [index_value])\n",
    "    bin_num_assoc_rowids = bytes([len(rowid_list)])\n",
    "    bin_indx_dtype = bytes(dt)\n",
    "    bin_index_val = val_dtype_to_byte(index_value, *dt)\n",
    "    bin_rowids = struct.pack(endian+str(len(rowid_list))+'i', *rowid_list)\n",
    "    payload = bin_num_assoc_rowids + bin_indx_dtype + bin_index_val+bin_rowids\n",
    "    return payload\n",
    "\n",
    "def index_payload_to_values(payload):\n",
    "    \"\"\"import bytestring payload from index cell outputs the index value and list of rowids\"\"\"\n",
    "    assoc_row_ids = payload[0]\n",
    "    indx_dtype = payload[1]\n",
    "\n",
    "    element_size = get_dt_size(indx_dtype)\n",
    "    indx_byte_str = payload[2:2+element_size]\n",
    "    indx_value = dtype_byte_to_val(indx_dtype, indx_byte_str)\n",
    "\n",
    "    bin_rowid_list  = payload[2+element_size:]\n",
    "\n",
    "    i=0\n",
    "    j = len(bin_rowid_list)\n",
    "    rowid_values = []\n",
    "    print(j)\n",
    "    while(i<j):\n",
    "        rowid_values.append(struct.unpack(endian+'i', bin_rowid_list[i:i+4])[0])\n",
    "        i+=4\n",
    "\n",
    "    return indx_value, rowid_values\n",
    "\n",
    "def table_create_cell(schema, value_list, is_interior, left_child_page=None,  rowid=None):\n",
    "    \"\"\"\n",
    "    Used to create a cell (binary string representation) that can be inserted into the tbl file\n",
    "\n",
    "    Parameters:\n",
    "    schema (list of strings):  ex. ['int', 'date', 'year']\n",
    "    value_list (list of python values):  ex. [10, '2016-03-23_00:00:00',2004]\n",
    "    is_interior (bool):  is the cell igoing into an interior or leaf page\n",
    "    left_child_page (int):  page_no of left child (only if cell is in interior page).\n",
    "    rowid (int):  rowid of the current cell (only if the cell is going in a leaf page)\n",
    "\n",
    "    Returns:\n",
    "    cell (byte-string): ex. b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n",
    "\n",
    "    \"\"\"\n",
    "    assert(len(value_list)==len(schema))\n",
    "    assert(type(schema)==list)\n",
    "    assert(type(value_list)==list)\n",
    "    assert(type(is_interior)==bool)\n",
    "\n",
    "    if  is_interior:\n",
    "        assert(left_child_page != None)\n",
    "        assert(rowid != None)\n",
    "        cell = struct.pack(endian+'ii', left_child_page, rowid)\n",
    "\n",
    "    else:\n",
    "        assert(rowid != None)\n",
    "        payload_body, dtypes  = table_values_to_payload(schema, value_list)\n",
    "        payload_header = bytes([len(dtypes)]) + bytes(dtypes)\n",
    "        cell_payload = payload_header + payload_body\n",
    "\n",
    "\n",
    "        cell_header = struct.pack(endian+'hi', len(cell_payload), rowid)\n",
    "\n",
    "        cell = cell_header + cell_payload\n",
    "\n",
    "    return cell\n",
    "\n",
    "def index_create_cell(index_dtype, index_value, rowid_list, is_interior, left_child_page=None):\n",
    "    \"\"\"\n",
    "    Used to create a cell (binary string representation) that can be inserted into the ndx file\n",
    "\n",
    "    Parameters:\n",
    "    index_dtype (string): ex\"long\"\n",
    "    index_value (val):  ex' 1037843\n",
    "    rowid_list (list of ints):  [100,22,3214]\n",
    "    is_interior (bool):\n",
    "    left_child_page (int):  only if cell is for interior cell\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    cell (byte-string): ex. b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n",
    "\n",
    "    \"\"\"\n",
    "    assert(type(is_interior)==bool)\n",
    "    is_leaf = not is_interior\n",
    "\n",
    "    payload = index_dtype_value_rowids_to_payload(index_dtype, index_value, rowid_list)\n",
    "    if is_interior:\n",
    "        assert(left_child_page != None)\n",
    "        cell_header = struct.pack(endian+'IH', left_child_page, len(payload))\n",
    "    elif is_leaf:\n",
    "        cell_header = struct.pack(endian+'H', len(payload))\n",
    "    else:\n",
    "         raise ValueError(\"Page must be either table\")\n",
    "\n",
    "    cell = cell_header + payload\n",
    "    return cell\n",
    "\n",
    "def table_read_cell(cell, is_interior):\n",
    "    \"\"\"\n",
    "    Used to read the contents of a cell (byte string)\n",
    "\n",
    "    Parameters:\n",
    "    cell (byte-string): ex b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n",
    "    is_interior (bool):\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    values (dictionary): ex.\n",
    "    interior-> {'left_child_rowid': 1, 'rowid': 10, 'cell_size': 8}\n",
    "    leaf ->{'bytes_in_payload': 61,'num_columns': 10,\n",
    "            'data': [2, 2, 12,10,10, 1.2999999523162842, None,2020, None,10, 10,'hist'],\n",
    "            'cell_size': 67}\n",
    "\n",
    "    \"\"\"\n",
    "    is_leaf = not is_interior\n",
    "\n",
    "    if  is_interior:\n",
    "        cell_header = struct.unpack(endian+'ii', cell[0:8])\n",
    "        res = {'left_child_page':cell_header[0],'rowid':cell_header[1]}\n",
    "    elif is_leaf:\n",
    "        cell_header = struct.unpack(endian+'hi', cell[0:6])\n",
    "        payload = cell[6:]\n",
    "        values = table_payload_to_values(payload)\n",
    "        res = {'bytes':cell_header[0]+6, 'rowid':cell_header[1],\"data\":values}\n",
    "    else:\n",
    "        print(\"error in read cell\")\n",
    "    res[\"cell_size\"]=len(cell)\n",
    "    return res\n",
    "\n",
    "def index_read_cell(cell, is_interior):\n",
    "    \"\"\"\n",
    "    Used to read the contents of a cell (byte string)\n",
    "\n",
    "    Parameters:\n",
    "    cell (byte-string): ex b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n",
    "    is_interior (bool):\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    values (dictionary):\n",
    "    interior -> {'lchild': 12,'index_value': 1000,'assoc_rowids': [1, 2, 3, 4],'cell_size': 32}\n",
    "    leaf-> {'index_value': 1000, 'assoc_rowids': [1, 2, 3, 4], 'cell_size': 28}\n",
    "\n",
    "    \"\"\"\n",
    "    result=dict()\n",
    "    if  is_interior:\n",
    "        cell_header = struct.unpack(endian+'ih', cell[0:6])\n",
    "        result[\"left_child_page\"]=cell_header[0]\n",
    "        result[\"bytes\"]=cell_header[0]+6\n",
    "        payload = cell[6:]\n",
    "    else:\n",
    "        cell_header = struct.unpack(endian+'h', cell[0:2])\n",
    "        result[\"bytes\"]=cell_header[0]+6\n",
    "        payload = cell[2:]\n",
    "\n",
    "    indx_value, rowid_list = index_payload_to_values(payload)\n",
    "    result[\"index_value\"]=indx_value\n",
    "    result[\"assoc_rowids\"]=rowid_list\n",
    "    result[\"cell_size\"]=len(cell)\n",
    "    return result\n",
    "\n",
    "\n",
    "def save_page(file_name, page_num, new_page_data):\n",
    "    \"\"\"\n",
    "    Saves the overwrites the page in the file (at loc- page_num) with a byte-string of length PAGE_SIZE\n",
    "\n",
    "    Parameters:\n",
    "    file_name (string): ex 'taco.tbl'\n",
    "    page_num (int): 1\n",
    "    new_page_data(bytestring): b'\\r\\x00\\x07\\x00\\n\\x01\\x00\\x00\\x00\\x00\\xff\\xff\\xff\\xff\\x00\\x00\\xe0\\x01\\xc0\\x01\\xa4\\x01\\x80\\x01\\\\\\x013\\x01\\n\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    assert(len(new_page_data)==PAGE_SIZE)\n",
    "    file_offset = page_num*PAGE_SIZE\n",
    "    with open(file_name, 'wb') as f:\n",
    "        f.seek(0, file_offset)\n",
    "        page = f.write(new_page_data)\n",
    "    return None\n",
    "\n",
    "\n",
    "def page_available_bytes(file_bytes, page_num):\n",
    "    page = load_page(file_bytes, page_num)\n",
    "    num_cells = struct.unpack(endian+'h', page[2:4])[0]\n",
    "    bytes_from_top = 16+(2*num_cells)\n",
    "    cell_content_start =struct.unpack(endian+'h', page[4:6])[0]\n",
    "    return  cell_content_start - bytes_from_top\n",
    "\n",
    "\n",
    "def page_insert_cell(file_name, page_num, cell):\n",
    "    \"\"\"\n",
    "    Inserts a bytestring into a page from a table or index file. Updates the page header. Fails if page-full\n",
    "\n",
    "    Parameters:\n",
    "    file_name (string): ex 'taco.tbl'\n",
    "    page_num (int): 1\n",
    "    cell (byte-string): ex b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    file_bytes = load_file(file_name)\n",
    "    page = load_page(file_bytes, page_num)\n",
    "\n",
    "    assert(len(cell)<page_available_bytes(file_bytes, page_num)) #CHECK IF PAGE FULL\n",
    "    num_cells = struct.unpack(endian+'h', page[2:4])[0]\n",
    "    bytes_from_top = 16+(2*num_cells)\n",
    "    bytes_from_bot =struct.unpack(endian+'h', page[4:6])[0]\n",
    "    new_start_index = bytes_from_bot - len(cell)\n",
    "    new_page_data = bytearray(page)\n",
    "    #insert cell data\n",
    "    new_page_data[new_start_index:bytes_from_bot] = cell\n",
    "    #add to 2byte cell array\n",
    "    new_page_data[bytes_from_top:bytes_from_top+2] = struct.pack(endian+'h', new_start_index)\n",
    "    #update start of cell content\n",
    "    new_page_data[4:6] = struct.pack(endian+'h', new_start_index)\n",
    "    #update num_cells\n",
    "    new_page_data[2:4] = struct.pack(endian+'h', num_cells+1)\n",
    "    save_page(file_name, page_num, new_page_data)\n",
    "    assert(len(new_page_data)==PAGE_SIZE)\n",
    "    return None\n",
    "\n",
    "def shift_page_content(page, top_indx, bot_indx, shift_step, up=True):\n",
    "    assert(bot_indx+shift_step<=PAGE_SIZE)\n",
    "    assert(top_indx-shift_step>=0)\n",
    "    if shift_step==0:\n",
    "        return page\n",
    "\n",
    "    copy = page[top_indx:bot_indx]\n",
    "    if up:\n",
    "        new_top_indx = top_indx - shift_step\n",
    "        new_bot_indx = bot_indx - shift_step\n",
    "        page[new_top_indx:new_bot_indx]=copy\n",
    "        page[new_bot_indx:bot_indx]=b'\\x00'*shift_step\n",
    "        return page\n",
    "    else:\n",
    "        new_top_indx = top_indx + shift_step\n",
    "        new_bot_indx = bot_indx + shift_step\n",
    "        page[new_top_indx:new_bot_indx]=copy\n",
    "        page[top_indx:new_top_indx]=b'\\x00'*shift_step\n",
    "        return page\n",
    "\n",
    "\n",
    "def update_array_values(page, first_array_loc_to_change, num_cells, shift_step, up=True):\n",
    "    \"\"\"When we shift the page content for cells, the pointers in the page header become incorrect.\"\"\"\n",
    "    if shift_step==0:\n",
    "        return page\n",
    "    if up:\n",
    "        for i in range(first_array_loc_to_change, num_cells):\n",
    "            arr_top = 16+2*i\n",
    "            arr_bot = 16+2*(i+1)\n",
    "            prev_val = struct.unpack(endian+'h',page[arr_top:arr_bot])[0]\n",
    "            page[arr_top:arr_bot]=struct.pack(endian+'h', prev_val-shift_step)\n",
    "    else:\n",
    "        for i in range(first_array_loc_to_change, num_cells):\n",
    "            arr_top = 16+2*i\n",
    "            arr_bot = 16+2*(i+1)\n",
    "            prev_val = struct.unpack(endian+'h',page[arr_top:arr_bot])[0]\n",
    "            page[arr_top:arr_bot]=struct.pack(endian+'h', prev_val+shift_step)\n",
    "    return page\n",
    "\n",
    "\n",
    "\n",
    "def page_delete_cell(file_name, page_num, cell_indx):\n",
    "    \"\"\"\n",
    "    Deletes a bytestring into a page from a table or index file. Updates the page header. Fails index given is out of bounds (2, when there is only one cell in page)\n",
    "    Fails if page is empty (no cells). RETURNS IS_EMPTY FLAG (empty after deletion)\n",
    "\n",
    "    Parameters:\n",
    "    file_name (string): ex 'taco.tbl'\n",
    "    page_num (int): 1\n",
    "    cell (byte-string): ex b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n",
    "\n",
    "    Returns:\n",
    "    is_empty (bool): False\n",
    "    \"\"\"\n",
    "    file_bytes = load_file(file_name)\n",
    "    page = load_page(file_bytes, page_num)\n",
    "    page = bytearray(temp_page)\n",
    "    num_cells = struct.unpack(endian+'h', page[2:4])[0]\n",
    "    assert(cell_indx<=num_cells-1)#index starts at 0\n",
    "    assert(num_cells>=1) #delete CAN empty a page\n",
    "    assert(cell_indx>=0)\n",
    "\n",
    "    cell_content_area_start = struct.unpack(endian+'h', page[4:6])[0]\n",
    "    end_of_array = 16+2*num_cells\n",
    "    array_idx_top = 16+2*idx\n",
    "    array_idx_bot = 16+2*(idx+1)\n",
    "\n",
    "    #if cell is the last cell (but not if theres only one cell left)\n",
    "    if (idx==num_cells-1) & (idx!=0):\n",
    "        cell_top_loc = cell_content_area_start\n",
    "        cell_bot_loc = struct.unpack(endian+'h',page[16+2*(idx-1):16+2*(idx)])[0]\n",
    "\n",
    "        cell_2_delete = page[cell_content_area_start:cell_bot_loc]\n",
    "        dis2replace= len(cell_2_delete)\n",
    "        #overwrite the cell2delete\n",
    "        page[cell_top_loc:cell_bot_loc]=b'\\x00'*dis2replace\n",
    "        #change the cell_start area in header\n",
    "        page[4:6] = struct.pack(endian+'h', cell_content_area_start+dis2replace)\n",
    "        #delete last entri in cell array\n",
    "        page[16+2*(num_cells-1):16+2*(num_cells)]=b'\\x00'*2\n",
    "        #update the number of cells\n",
    "        page[2:4] = struct.pack(endian+'h', num_cells-1)\n",
    "\n",
    "    else:\n",
    "        cell_top_loc = struct.unpack(endian+'h',page[array_idx_top:array_idx_bot])[0]\n",
    "        if idx==0: #if cell is first on the page (bottom)\n",
    "            cell_bot_loc = PAGE_SIZE\n",
    "        else:\n",
    "            cell_bot_loc = struct.unpack(endian+'h',page[array_idx_top-2:array_idx_top])[0]\n",
    "\n",
    "        cell_2_delete = page[cell_top_loc:cell_bot_loc]\n",
    "        dis2replace= len(cell_2_delete)\n",
    "        #shift cell content down\n",
    "        page = shift_page_content(page, cell_content_area_start, cell_top_loc, dis2replace, up=False)\n",
    "        #since we just shifted every cell, every value in cell_array is off\n",
    "        page = update_array_values(page, cell_indx, num_cells, dis2replace, up=False)\n",
    "        #change the cell_start area\n",
    "        page[4:6] = struct.pack(endian+'h', cell_content_area_start+dis2replace)\n",
    "        #shift cell array up (deletes entry for deleted cell)\n",
    "        page = shift_page_content(page, array_idx_bot, end_of_array, 2, up=True)\n",
    "        #update num of cells\n",
    "        page[2:4] = struct.pack(endian+'h', num_cells-1)\n",
    "\n",
    "    save_page(file_name, page_num, page)\n",
    "    assert(len(new_page_data)==PAGE_SIZE) #ensure page is same size\n",
    "    return (num_cells - 1) == 0\n",
    "\n",
    "\n",
    "\n",
    "def merge_pages(file_bytes, parent_num, lchild_num, rchild_num):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def load_file(file_name):\n",
    "    \"\"\"loads the table/index file returns the bytestring for the entire file (reduce number of read/writes)\n",
    "\n",
    "    Parameters:\n",
    "    file (byte-string): ex 'taco.tbl'\n",
    "    page_num (int): 1\n",
    "\n",
    "    Returns:\n",
    "    page (bytestring):\n",
    "    \"\"\"\n",
    "    with open(file_name, 'rb') as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def load_page(file_bytes, page_num):\n",
    "    \"\"\"\n",
    "    loads the page of from the table/index PAGE NUMBER STARTS AT ZERO, will only load one pa\n",
    "    Parameters:\n",
    "    file_name (string): ex 'taco.tbl'\n",
    "    page_num (int): 1\n",
    "    Returns:\n",
    "    page (bytestring):\n",
    "    \"\"\"\n",
    "    file_offset = page_num*PAGE_SIZE\n",
    "    return file_bytes[file_offset:(page_num+1)*PAGE_SIZE]\n",
    "\n",
    "def read_cells_in_page(file_bytes, page_num):\n",
    "    \"\"\"read all the data from a page, get the file_bytes object with load_file(file_name)\"\"\"\n",
    "    assert(page_num<(len(file_bytes)/PAGE_SIZE))\n",
    "    page = load_page(file_bytes, page_num)\n",
    "\n",
    "    num_cells = struct.unpack(endian+'h', page[2:4])[0]\n",
    "    parent_page = struct.unpack(endian+'i', page[10:14])[0]\n",
    "    available_bytes = page_available_bytes(file_bytes, page_num)\n",
    "    if page[0] in [5,13]:\n",
    "        is_table = True\n",
    "    else:\n",
    "        is_table = False\n",
    "\n",
    "    if page[0] in [2,5]:\n",
    "        is_interior = True\n",
    "    else:\n",
    "        is_interior = False\n",
    "\n",
    "    i=0\n",
    "    data = []\n",
    "    while i<=num_cells-1:\n",
    "        if i == 0:\n",
    "            cell_bot_loc = PAGE_SIZE\n",
    "        else:\n",
    "            cell_bot_loc = struct.unpack(endian+'h',page[16+2*(i-1):16+2*(i)])[0]\n",
    "        cell_top_loc = struct.unpack(endian+'h',page[16+2*i:16+2*(i+1)])[0]\n",
    "\n",
    "        cell = page[cell_top_loc:cell_bot_loc]\n",
    "\n",
    "        if is_table:\n",
    "            data.append(table_read_cell(cell, is_interior))\n",
    "        else:\n",
    "            data.append(index_read_cell(cell, is_interior))\n",
    "        i+=1\n",
    "\n",
    "    result = {\n",
    "    \"page_number\":page_num,\n",
    "    \"parent_page\":parent_page,\n",
    "    \"is_table\": is_table,\n",
    "    \"is_leaf\": not is_interior,\n",
    "    \"num_cells\":num_cells,\n",
    "    \"available_bytes\":available_bytes,\n",
    "    \"cells\":data\n",
    "    }\n",
    "    if is_interior:\n",
    "        result['rightmost_child_page'] = parent_page = struct.unpack(endian+'i', page[6:10])[0]\n",
    "    else:\n",
    "        result['rightmost_sibling_page'] = parent_page = struct.unpack(endian+'i', page[6:10])[0]\n",
    "\n",
    "    return result\n",
    "\n",
    "def read_all_pages_in_file(file_name):\n",
    "    \"\"\"\n",
    "    Given the file name, loads all data from every page. This is what we will use during inserts updates, deletes\n",
    "\n",
    "    Parameters:\n",
    "    file_name (string): ex\"davisbase_tables.tbl\"\n",
    "\n",
    "    Returns:\n",
    "    pages (dict of dicts): ex. b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n",
    "\n",
    "    \"\"\"\n",
    "    if file_name[-3:]=='tbl':\n",
    "        is_table=True\n",
    "    else:\n",
    "        is_table = False\n",
    "\n",
    "    file = load_file(file_name)\n",
    "    file_size = len(file)\n",
    "    assert(file_size%PAGE_SIZE==0)\n",
    "    num_pages = int(file_size/PAGE_SIZE)\n",
    "    data = []\n",
    "    for page_num in range(num_pages):\n",
    "        data.append(read_cells_in_page(file, page_num))\n",
    "    return data\n",
    "\n",
    "def find_value_page():\n",
    "    ## \n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "\n",
    "\n",
    "def insert_cell_index(table_name, page_num, schema, values):\n",
    "    return\n",
    "\n",
    "def delete_cell_index(table_name, page_num, schema, values):\n",
    "    return\n",
    "\n",
    "def delete_cell_index(table_name, page_num, schema, values):\n",
    "    return\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "class Table:\n",
    "    def __init__(table_name, create=False):\n",
    "        if create:\n",
    "            #do this last\n",
    "            if catalog.check_table_exists(table_name):\n",
    "                create_file() #todo\n",
    "                update_catalogue() #leave these for later\n",
    "            else:\n",
    "                printe(\"error\")\n",
    "\n",
    "        self.table_name = table_name\n",
    "        self.file_name = table_name+'.tbl'\n",
    "        self.column_list = catalog.get_columnlist(table_name) #will use this in inserts/update to check constraints\n",
    "        self.num_pages = 0 #get file size, divide by page_size\n",
    "        self.root_page = Table_Page(table_name, 0)\n",
    "        self.indexed_columns = [col if col.primary_key==True else '' for col in self.column_list]\n",
    "        self.schema =['list of datatypes in ints (from documentation)']\n",
    "        self.next_available_rowid = 0\n",
    "\n",
    "\n",
    "    def get_cell_page(order_key):\n",
    "        return \"cell_page_no\"\n",
    "\n",
    "    def insert(values):\n",
    "        \"\"\"values would be a list of length self.columns, NULL represented as None\"\"\"\n",
    "        #get dtypes\n",
    "        #check dtypes match\n",
    "        #get_next_rowid\n",
    "        #check constraints\n",
    "        #create_cell\n",
    "        #find_page\n",
    "        #insert_cell2tablepage\n",
    "        return \"success_flag\"\n",
    "\n",
    "    def update(order_key, values):\n",
    "        \"\"\"update a single cell\"\"\"\n",
    "        #get_page\n",
    "        #cell\n",
    "\n",
    "    def delete(order_key, values):\n",
    "        \"\"\"delete a single cell from a page/ (will be used in a loop once we figure out queries)\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "class Table_Page:\n",
    "    def __init__(table_name, page_num):\n",
    "        self.page_number = page_num\n",
    "        self.table_name = table_name\n",
    "        self.parent = 0\n",
    "        self.is_leaf = True\n",
    "        self.sibling = 0\n",
    "        self.child = 0\n",
    "        self.num_cells = 0\n",
    "    def check_pk_indata():\n",
    "        return False\n",
    "\n",
    "\n",
    "class Index:\n",
    "    def __init__(index_name ,assoc_table, create=False):\n",
    "        if create:\n",
    "            #do this last\n",
    "            if catalog.check_table_exists(table_name):\n",
    "                create_file() #todo\n",
    "                update_catalogue() #leave these for later\n",
    "            else:\n",
    "                printe(\"error\")\n",
    "\n",
    "        self.assoc_table = assoc_table\n",
    "        self.file_name = index_name+'.tbl'\n",
    "        self.num_pages = 0 #get file size, divide by page_size\n",
    "        self.root_page = Page(index_name, 0)\n",
    "        self.next_available_rowid = 0\n",
    "\n",
    "\n",
    "    def get_cell_page(order_key):\n",
    "        return \"cell_page_no\"\n",
    "\n",
    "    def insert(values):\n",
    "        \"\"\"values would be a list of length self.columns, NULL represented as None\"\"\"\n",
    "        #get dtypes\n",
    "        #check dtypes match\n",
    "        #get_next_rowid\n",
    "        #check constraints\n",
    "        #create_cell\n",
    "        #find_page\n",
    "        #insert_cell2tablepage\n",
    "        return \"success_flag\"\n",
    "\n",
    "    def update(order_key, values):\n",
    "        \"\"\"update a single cell\"\"\"\n",
    "        #get_page\n",
    "        #cell\n",
    "\n",
    "    def delete(order_key, values):\n",
    "        \"\"\"delete a single cell from a page/ (will be used in a loop once we figure out queries)\"\"\"\n",
    "\n",
    "\n",
    "class Index_Page:\n",
    "    def __init__(table_name, page_num):\n",
    "        self.page_number = page_num\n",
    "        self.table_name = table_name\n",
    "        self.parent = 0\n",
    "        self.is_leaf = True\n",
    "        self.sibling = 0\n",
    "        self.child = 0\n",
    "        self.num_cells = 0\n",
    "    def check_pk_indata():\n",
    "        return False\n",
    "\n",
    "\n",
    "class Column:\n",
    "    #I want to use this object rather than a dict because the code will be cleaner\n",
    "    #later on, we can just iterate through the columns\n",
    "    def __init__(column_name, dtype, not_null, unique, primary_key):\n",
    "        self.column_name = column_name\n",
    "        self.dtype = dtype\n",
    "        self.not_null = not_null\n",
    "        self.unique = unique\n",
    "        self.primary_key = pk\n",
    "\n",
    "class Catalog:\n",
    "    def __init__():\n",
    "        return\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "#CLI FUNCTIONS\n",
    "\n",
    "def init():\n",
    "    if os.path.exists('davisbase_columns.tbl'):\n",
    "        pass\n",
    "    else:\n",
    "        initialize_file('davisbase_columns', True)\n",
    "        file_name = \"davisbase_columns.tbl\"\n",
    "        davisbase_columns_schema = ['TEXT', 'TEXT', 'TEXT', 'TINYINT', 'TEXT']\n",
    "\n",
    "        cells = [[\"davisbase_tables\", \"rowid\", \"INT\", 1, \"NO\" ],\n",
    "                [\"davisbase_tables\", \"table_name\", \"TEXT\", 2, \"NO\" ],\n",
    "                 [\"davisbase_columns\", \"rowid\", \"INT\", 1, \"NO\" ],\n",
    "                [\"davisbase_columns\", \"table_name\", \"TEXT\", 2, \"NO\" ],\n",
    "                [\"davisbase_columns\", \"column_name\", \"TEXT\", 3, \"NO\" ],\n",
    "                [\"davisbase_columns\", \"data_type\", \"TEXT\", 4, \"NO\" ],\n",
    "                [\"davisbase_columns\", \"ordinal_position\", \"TINYINT\", 5, \"NO\" ],\n",
    "                [\"davisbase_columns\", \"is_nullable\", \"TEXT\", 6, \"NO\" ]]\n",
    "\n",
    "        for i, cell in enumerate(cells):\n",
    "            cell = table_create_cell(davisbase_columns_schema, cell, False, left_child_page=None,  rowid=i+1)\n",
    "            try:\n",
    "                page_insert_cell(file_name, 0, cell)\n",
    "            except:\n",
    "                print(\"cell_size:\",len(cell))\n",
    "                file_bytes = load_file(file_name)\n",
    "                print(\"Remaining space in page:\", page_available_bytes(file_bytes, 0))\n",
    "\n",
    "\n",
    "    if os.path.exists('davisbase_tables.tbl'):\n",
    "        pass\n",
    "    else:\n",
    "        initialize_file('davisbase_tables', True)\n",
    "        file_name = \"davisbase_tables.tbl\"\n",
    "        davisbase_tables_schema = ['TEXT']\n",
    "\n",
    "        cells = [[\"davisbase_tables\"],\n",
    "                [\"davisbase_columns\"]]\n",
    "\n",
    "        for i, cell in enumerate(cells):\n",
    "            cell = table_create_cell(davisbase_tables_schema, cell, False, left_child_page=None,  rowid=i+1)\n",
    "            try:\n",
    "                page_insert_cell(file_name, 0, cell)\n",
    "            except:\n",
    "                print(\"cell_size:\",len(cell))\n",
    "                file_bytes = load_file(file_name)\n",
    "                print(\"Remaining space in page:\", page_available_bytes(file_bytes, 0))\n",
    "\n",
    "def help():\n",
    "    print(\"DavisBase supported commands.\")\n",
    "    print(\"##########################################\")\n",
    "    print(\"SHOW TABLES;\")\n",
    "    print(\"CREATE TABLE ...;\")\n",
    "    print(\"DROP TABLE ...;\")\n",
    "    print(\"CREATE INDEX ...;\")\n",
    "    print(\"INSERT INTO ...;\")\n",
    "    print(\"DELETE FROM ...;\")\n",
    "    print(\"UPDATE ...\")\n",
    "    print(\"SELECT ...;\")\n",
    "    print(\"EXIT;\")\n",
    "    return None\n",
    "\n",
    "#########################################################################\n",
    "# DDL FUNCTION\n",
    "\n",
    "def show_tables():\n",
    "    \"\"\"\n",
    "    This can be implemented by querying dabisbase_tables\n",
    "    \"\"\"\n",
    "    print(\"ALL TABLES\")\n",
    "    return None\n",
    "\n",
    "def create_table(command):\n",
    "    table_name, column_list = parse_create_table(command)\n",
    "    with open(table_name+'.db', 'w+') as f:\n",
    "        pass\n",
    "\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def extract_definitions(token_list):\n",
    "    '''\n",
    "    Subordinate function for create table to get column names and their definitions\n",
    "    '''\n",
    "\n",
    "    # assumes that token_list is a parenthesis\n",
    "    definitions = []\n",
    "    tmp = []\n",
    "    # grab the first token, ignoring whitespace. idx=1 to skip open (\n",
    "    tidx, token = token_list.token_next(1)\n",
    "    while token and not token.match(sqlparse.tokens.Punctuation, ')'):\n",
    "        tmp.append(token)\n",
    "        # grab the next token, this times including whitespace\n",
    "        tidx, token = token_list.token_next(tidx, skip_ws=False)\n",
    "        # split on \",\", except when on end of statement\n",
    "        if token and token.match(sqlparse.tokens.Punctuation, ','):\n",
    "            definitions.append(tmp)\n",
    "            tmp = []\n",
    "            tidx, token = token_list.token_next(tidx)\n",
    "    if tmp and isinstance(tmp[0], sqlparse.sql.Identifier):\n",
    "        definitions.append(tmp)\n",
    "    return definitions\n",
    "\n",
    "def parse_create_table(SQL):\n",
    "    \"\"\"\n",
    "    Parses the raw, lower-cased input from the CLI controller. Will identify table name,\n",
    "    column names, data types, and constraints. Will also check for syntax errors.\n",
    "    Also check that table_name is all characters (no punctuation spaces...)\n",
    "\n",
    "    Parameters:\n",
    "    command (string):  lower-case string from CLI.\n",
    "    (ex. \"CREATE TABLE table_name (\n",
    "             column_name1 data_type1 [NOT NULL][UNIQUE],\n",
    "             column_name2 data_type2 [NOT NULL][UNIQUE],\n",
    "            );\"\"  )\n",
    "\n",
    "    Returns:\n",
    "    tuple: (table_name, column_list, definition_list)\n",
    "\n",
    "    table_name: str\n",
    "    column_list: list of column objects.\n",
    "\n",
    "    SQL = \\\"\"\"CREATE TABLE foo (\n",
    "         id integer primary key,\n",
    "         title varchar(200) not null,\n",
    "         description text);\\\"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    if re.match(\"(?i)create (?i)table [a-zA-Z]+\\s\\(\\s?\\n?\", SQL):\n",
    "        if SQL.endswith(');'):\n",
    "            print(\"Valid statement\")\n",
    "    else:\n",
    "        print(\"Invalid statement\")\n",
    "\n",
    "    parsed = sqlparse.parse(SQL)[0]\n",
    "    table_name = str(parsed[4])\n",
    "    _, par = parsed.token_next_by(i=sqlparse.sql.Parenthesis)\n",
    "    columns = extract_definitions(par)\n",
    "    col_list = []\n",
    "    definition_list = []\n",
    "    for column in columns:\n",
    "        definitions = ''.join(str(t) for t in column).split(',')\n",
    "        for definition in definitions:\n",
    "            d = ' '.join(str(t) for t in definition.split())\n",
    "            print('NAME: {name} DEFINITION: {definition}'.format(name=definition.split()[0],\n",
    "                                                                 definition=d))\n",
    "            col_list.append(definition.split()[0])\n",
    "            definition_list.append(d)\n",
    "\n",
    "    ## table name and two lists columns and definitions\n",
    "    return (table_name,col_list, definition_list)\n",
    "\n",
    "\n",
    "\n",
    "def drop_table(command):\n",
    "    table_name = parse_drop_table(command)\n",
    "    if check_table_exists(table_name):\n",
    "        success = delete_all_table_data(table_name)\n",
    "        if not success:\n",
    "            print(\"temporary error\")\n",
    "    else:\n",
    "        print(\"Table \\\"{}\\\" does note exist.\".format(table_name))\n",
    "\n",
    "def parse_drop_table(command):\n",
    "    \"\"\"\n",
    "    Parses the raw, lower-cased input from the CLI controller. Will identify table name,\n",
    "    Will also check for syntax errors. Throw error if\n",
    "\n",
    "    Parameters:\n",
    "    command (string):  lower-case string from CLI. (ex. \"drop table table_name;\"\" )\n",
    "\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    ## check if the drop statement is correct or not\n",
    "    ## statement must compulsarily end with semicolon\n",
    "    query_match = \"(?i)DROP\\s+(.*?)\\s*(?i)TABLE\\s+[a-zA-Z]+\\;\"\n",
    "    if re.match(query_match, command):\n",
    "        stmt = sqlparse.parse(command)[0]\n",
    "        tablename = str(stmt.tokens[-2])\n",
    "    else:\n",
    "        print(\"Enter correct query\")\n",
    "    return tablename\n",
    "\n",
    "def check_table_exists(table_name):\n",
    "    \"\"\"\n",
    "    Checks if the table exists in davisbase_tables.tbl\n",
    "\n",
    "    Returns:\n",
    "    bool: table_exists\n",
    "    \"\"\"\n",
    "    return False\n",
    "\n",
    "\n",
    "def delete_all_table_data(table_name):\n",
    "    \"\"\"\n",
    "    Deletes table_name.tbl, check if index exists (if so, delete index), update metadata remove all cells related to table_name\n",
    "\n",
    "    Returns:\n",
    "    bool: success_flag\n",
    "    \"\"\"\n",
    "    return False\n",
    "\n",
    "\n",
    "def catalog_add_table(dictionary, rowid):\n",
    "    \"\"\"\n",
    "    dictionary = {\n",
    "    'table_name':{\n",
    "        \"column1\":{\n",
    "            'data_type':\"int\",\n",
    "            'ordinal_position':1,\n",
    "            'is_nullable':'YES',\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    table = list(dictionary.keys())\n",
    "    assert(len(table)==1)\n",
    "    table_name = table[0]\n",
    "\n",
    "    davisbase_tables_schema = ['text']\n",
    "    davisbase_columns_schema = ['text', 'text', 'text', 'int', 'text']\n",
    "\n",
    "\n",
    "def create_index(command):\n",
    "    print(\"create index \\'{}\\'\".format(command))\n",
    "    return None\n",
    "\n",
    "############################################################################\n",
    "#DML FUNCTIONS\n",
    "\n",
    "############################################################################\n",
    "#DML FUNCTIONS\n",
    "\n",
    "def insert_into(command):\n",
    "    '''\n",
    "    Assuming values are being set along the correct order of columns\n",
    "    '''\n",
    "    print(\"Insert into \\'{}\\'\".format(command))\n",
    "    query_match = \"insert into\\s+(.*?)\\s*((?i)values\\s(.*?)\\s*)?;\"\n",
    "    if re.match(query_match, command):\n",
    "        stmt = sqlparse.parse(command)[0]\n",
    "        table_name = str(stmt.tokens[4])\n",
    "        values = str(stmt.tokens[-2])\n",
    "        values = re.sub(\"\\s\", \"\", re.split(';',re.sub(\"(?i)values\",\"\",values))[0])\n",
    "        print(values,\"\\t\",table_name)\n",
    "    else:\n",
    "        print(\"Enter correct query\")\n",
    "\n",
    "def delete_from(command):\n",
    "    print(\"delete from \\'{}\\'\".format(command))\n",
    "    ## check if the update statement is correct or not\n",
    "    query_match = \"delete\\s+(.*?)\\s*(?i)from\\s+(.*?)\\s*((?i)where\\s(.*?)\\s*)?;\"\n",
    "    if re.match(query_match, command):\n",
    "        stmt = sqlparse.parse(command)[0]\n",
    "        where_clause = str(stmt.tokens[-1])\n",
    "        where_clause = re.sub(\"\\s\", \"\", re.split(';',re.sub(\"(?i)where\",\"\",where_clause))[0])\n",
    "        where_clause = re.split('=|>|<|>=|<=|\\s',where_clause)\n",
    "        tablename = str(stmt.tokens[-3]).split(\",\")\n",
    "        print(where_clause,\"\\t\",tablename)\n",
    "    else:\n",
    "        print(\"Enter correct query\")\n",
    "\n",
    "\n",
    "def update(command):\n",
    "    print(\"update \\'{}\\'\".format(command))\n",
    "    ## check if the update statement is correct or not\n",
    "    query_match = \"(?i)update\\s+(.*?)\\s*(?i)set\\s+(.*?)\\s*((?i)where\\s(.*?)\\s*)?;\"\n",
    "    if re.match(query_match, command):\n",
    "        stmt = sqlparse.parse(command)[0]\n",
    "        where_clause = str(stmt.tokens[-1])\n",
    "        where_clause = re.sub(\"\\s\", \"\", re.split(';',re.sub(\"(?i)where\",\"\",where_clause))[0])\n",
    "        where_clause = re.split('=|>|<|>=|<=|\\s',where_clause)\n",
    "        set_col = itemgetter(*[0,-1])(re.split('=|\\s',str(stmt.tokens[-3])))\n",
    "        tablename = str(stmt.tokens[2])\n",
    "        print(where_clause,\"\\t\", tablename,\"\\t\",set_col)\n",
    "        ## perform select logic\n",
    "    else:\n",
    "        print(\"Enter correct query\")\n",
    "\n",
    "##########################################################################\n",
    "#DQL FUNCTIONS\n",
    "\n",
    "def query(command: str):\n",
    "    '''\n",
    "    command : Select statement eg. select a.a,b.b,c from a,b where a.a = b.a;\n",
    "    return : None\n",
    "    '''\n",
    "    print(\"User wants to query {}\".format(command))\n",
    "    ## check if the select statement is correct or not\n",
    "    query_match = \"select\\s+(.*?)\\s*(?i)from\\s+(.*?)\\s*((?i)where\\s(.*?)\\s*)?;\"\n",
    "    if re.match(query_match, command):\n",
    "        stmt = sqlparse.parse(command)[0]\n",
    "        where_clause = str(stmt.tokens[-1])\n",
    "        where_clause = re.sub(\"\\s\", \"\", re.split(';',re.sub(\"(?i)where\",\"\",where_clause))[0])\n",
    "        where_clause = re.split('=|>|<|>=|<=|\\s',where_clause)\n",
    "        print(where_clause)\n",
    "        tablename = str(stmt.tokens[-3]).split(\",\")\n",
    "        columns = str(stmt.tokens[2]).split(\",\")\n",
    "        print(where_clause,\"\\t\",tablename,\"\\t\",columns)\n",
    "    else:\n",
    "        print(\"Enter correct query\")\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "PAGE_SIZE = 512\n",
    "BYTE_ORDER = sys.byteorder\n",
    "if BYTE_ORDER=='big':\n",
    "    endian = '>'\n",
    "elif BYTE_ORDER=='little':\n",
    "    endian = '<'\n",
    "\n",
    "if __name__== \"__main__\":\n",
    "    init()\n",
    "    read_all_pages_in_file(\"davisbase_columns.tbl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
